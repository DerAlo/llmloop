# LLM Loop - Ollama FTMO MQL5 Code Generator

Ein Python-Script das zwei Ollama LLMs orchestriert, um iterativ perfekten FTMO-konformen MQL5 Expert Advisor Code zu entwickeln.

## ğŸ¯ Funktionsweise

Das Script implementiert eine intelligente Kommunikationsschleife zwischen zwei spezialisierten LLMs:

- **qwen3:latest** (Instructor/Reviewer): Gibt Anweisungen und Ã¼berprÃ¼ft Code-QualitÃ¤t
- **qwen2.5-coder:latest** (Code Generator): Generiert und verbessert MQL5 Code

## ğŸ”„ Prozess

1. **Initiale Anweisung**: qwen3 erstellt detaillierte Anforderungen fÃ¼r einen FTMO EA
2. **Code-Generierung**: qwen2.5-coder schreibt MQL5 Code basierend auf den Anweisungen
3. **Code-Review**: qwen3 bewertet den Code nach FTMO-Kriterien und Code-QualitÃ¤t
4. **Iterative Verbesserung**: Bei Unzufriedenheit wird der Code Ã¼berarbeitet
5. **Finale Ausgabe**: Perfekter FTMO-konformer Expert Advisor Code

## ğŸ“‹ FTMO Anforderungen

Das Script berÃ¼cksichtigt alle wichtigen FTMO Challenge Regeln:
- Maximum Daily Loss: 5%
- Maximum Loss: 10% 
- Profit Target: 10%
- Minimum Trading Days: 5
- Maximum Trading Days: 30
- News Trading und Expert Advisors: Erlaubt

## ğŸš€ Installation & Setup

### Voraussetzungen

1. **Ollama installiert**: [ollama.ai](https://ollama.ai)
2. **Python 3.8+** installiert
3. **BenÃ¶tigte Modelle** in Ollama verfÃ¼gbar:
   ```bash
   ollama pull qwen3:latest
   ollama pull qwen2.5-coder:latest
   ```

### Installation

1. Dependencies installieren:
   ```bash
   pip install -r requirements.txt
   ```

2. Ollama Server starten:
   ```bash
   ollama serve
   ```

3. Script ausfÃ¼hren:
   ```bash
   python llm_loop.py
   ```

## ğŸ“Š Output

Das Script generiert:
- **FTMO_Expert_Advisor_[timestamp].mq5**: Finaler MQL5 Code
- **conversation_log_[timestamp].json**: VollstÃ¤ndige Konversation
- **llm_loop.log**: AusfÃ¼hrliche Logs

## âš™ï¸ Konfiguration

Anpassbare Parameter in `llm_loop.py`:
- `max_iterations`: Maximum Anzahl Verbesserungsiterationen (Standard: 10)
- `instructor_model`: Name des Instructor Modells
- `coder_model`: Name des Coder Modells
- `base_url`: Ollama API URL (Standard: http://localhost:11434)

## ğŸ”§ Features

- **Async/Await**: Effiziente API-Kommunikation
- **Farbiges Terminal**: Ãœbersichtliche Ausgabe mit colorama
- **Umfassendes Logging**: Detaillierte Protokollierung aller Schritte
- **Automatische Speicherung**: Code und Konversation werden automatisch gespeichert
- **Fehlerbehandlung**: Robuste Error-Handling fÃ¼r API-Calls
- **FTMO-Fokus**: Spezialisiert auf FTMO Challenge Anforderungen

## ğŸ“ Beispiel-Workflow

```
ğŸ¯ INSTRUCTOR GENERIERT ANFANGSANWEISUNG
â†“
ğŸ’» CODER GENERIERT MQL5 CODE
â†“
ğŸ” INSTRUCTOR REVIEWT CODE
â†“
ğŸ”§ CODER VERBESSERT CODE (falls notwendig)
â†“
ğŸ”„ Wiederholung bis Zufriedenheit
â†“
âœ… FINALER CODE GESPEICHERT
```

## ğŸ› ï¸ Troubleshooting

**Ollama nicht erreichbar:**
- PrÃ¼fen Sie ob Ollama lÃ¤uft: `ollama list`
- Server neu starten: `ollama serve`

**Modelle fehlen:**
```bash
ollama pull qwen3:latest
ollama pull qwen2.5-coder:latest
```

**Python Dependencies:**
```bash
pip install --upgrade -r requirements.txt
```

## ğŸ“„ Lizenz

Dieses Projekt ist fÃ¼r persÃ¶nliche und kommerzielle Nutzung freigegeben.
